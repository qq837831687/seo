#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SEOå…³é”®è¯æ•°æ®å¯è§†åŒ–æ¨¡å—
ç”Ÿæˆå¤šç§å›¾è¡¨å¸®åŠ©åˆ†æå…³é”®è¯æ•°æ®
"""

import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import pandas as pd
import numpy as np
from pathlib import Path
import json
from collections import Counter

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®é…è‰²æ–¹æ¡ˆ
sns.set_palette("husl")
sns.set_style("whitegrid")


class KeywordVisualizer:
    """å…³é”®è¯æ•°æ®å¯è§†åŒ–å™¨"""

    def __init__(self, output_dir="output/charts"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def generate_score_distribution(self, keywords_data):
        """ç”Ÿæˆå…³é”®è¯è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾"""
        scores = [data['score'] for _, data in keywords_data]

        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # ç›´æ–¹å›¾
        axes[0].hist(scores, bins=20, color='skyblue', edgecolor='black', alpha=0.7)
        axes[0].set_xlabel('è¯„åˆ†', fontsize=12)
        axes[0].set_ylabel('å…³é”®è¯æ•°é‡', fontsize=12)
        axes[0].set_title('å…³é”®è¯è¯„åˆ†åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        axes[0].grid(axis='y', alpha=0.3)

        # ç®±çº¿å›¾
        axes[1].boxplot(scores, vert=True, patch_artist=True,
                       boxprops=dict(facecolor='lightblue', alpha=0.7),
                       medianprops=dict(color='red', linewidth=2))
        axes[1].set_ylabel('è¯„åˆ†', fontsize=12)
        axes[1].set_title('è¯„åˆ†ç»Ÿè®¡ç®±çº¿å›¾', fontsize=14, fontweight='bold')
        axes[1].grid(axis='y', alpha=0.3)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_score = np.mean(scores)
        median_score = np.median(scores)
        axes[1].text(1.1, mean_score, f'å¹³å‡: {mean_score:.1f}', fontsize=10)
        axes[1].text(1.1, median_score, f'ä¸­ä½æ•°: {median_score:.1f}', fontsize=10)

        plt.tight_layout()
        output_path = self.output_dir / "score_distribution.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        return output_path

    def generate_intent_pie(self, keywords_data):
        """ç”Ÿæˆæ„å›¾æ ‡ç­¾é¥¼å›¾"""
        intents = []
        for _, data in keywords_data:
            intent = data['intent'].split('/')[0]  # å–ç¬¬ä¸€ä¸ªæ„å›¾
            intents.append(intent if intent else 'é€šç”¨')

        intent_counts = Counter(intents)

        # æŒ‰æ•°é‡æ’åº
        sorted_intents = dict(sorted(intent_counts.items(), key=lambda x: x[1], reverse=True))

        fig, ax = plt.subplots(figsize=(10, 8))

        colors = sns.color_palette("Set3", len(sorted_intents))
        wedges, texts, autotexts = ax.pie(
            sorted_intents.values(),
            labels=sorted_intents.keys(),
            autopct='%1.1f%%',
            colors=colors,
            startangle=90,
            textprops={'fontsize': 11}
        )

        # ç¾åŒ–æ–‡æœ¬
        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontweight('bold')

        ax.set_title('å…³é”®è¯æ„å›¾æ ‡ç­¾åˆ†å¸ƒ', fontsize=16, fontweight='bold', pad=20)

        # æ·»åŠ å›¾ä¾‹
        ax.legend(wedges, [f'{k}: {v}' for k, v in sorted_intents.items()],
                 title="æ„å›¾åˆ†ç±»",
                 loc="center left",
                 bbox_to_anchor=(1, 0, 0.5, 1))

        plt.tight_layout()
        output_path = self.output_dir / "intent_distribution.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        return output_path

    def generate_source_bar(self, keywords_data):
        """ç”Ÿæˆå…³é”®è¯æ¥æºåˆ†å¸ƒæ¡å½¢å›¾"""
        sources = []
        for _, data in keywords_data:
            source = data['source']
            sources.append(source)

        source_counts = Counter(sources)
        sorted_sources = dict(sorted(source_counts.items(), key=lambda x: x[1], reverse=True))

        fig, ax = plt.subplots(figsize=(10, 6))

        sources_list = list(sorted_sources.keys())
        counts_list = list(sorted_sources.values())

        colors = sns.color_palette("viridis", len(sources_list))
        bars = ax.barh(sources_list, counts_list, color=colors)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars, counts_list):
            width = bar.get_width()
            ax.text(width + 0.5, bar.get_y() + bar.get_height()/2,
                   f'{count}',
                   ha='left', va='center', fontsize=10, fontweight='bold')

        ax.set_xlabel('å…³é”®è¯æ•°é‡', fontsize=12)
        ax.set_ylabel('æ•°æ®æº', fontsize=12)
        ax.set_title('å„æ•°æ®æºå…³é”®è¯æ•°é‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax.grid(axis='x', alpha=0.3)

        plt.tight_layout()
        output_path = self.output_dir / "source_distribution.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        return output_path

    def generate_top_keywords_bar(self, keywords_data, top_n=20):
        """ç”ŸæˆTOPå…³é”®è¯æ¡å½¢å›¾"""
        top_keywords = keywords_data[:top_n]

        keywords_list = [kw for kw, _ in top_keywords]
        scores_list = [data['score'] for _, data in top_keywords]

        fig, ax = plt.subplots(figsize=(12, 8))

        colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(keywords_list)))
        bars = ax.barh(range(len(keywords_list)), scores_list, color=colors)

        # è®¾ç½®Yè½´æ ‡ç­¾
        ax.set_yticks(range(len(keywords_list)))
        ax.set_yticklabels(keywords_list, fontsize=9)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, score) in enumerate(zip(bars, scores_list)):
            width = bar.get_width()
            ax.text(width + 0.3, bar.get_y() + bar.get_height()/2,
                   f'{score}',
                   ha='left', va='center', fontsize=9, fontweight='bold')

        ax.set_xlabel('è¯„åˆ†', fontsize=12)
        ax.set_title(f'TOP {top_n} é«˜åˆ†å…³é”®è¯', fontsize=14, fontweight='bold')
        ax.grid(axis='x', alpha=0.3)

        # åè½¬Yè½´ï¼Œè®©æœ€é«˜çš„åœ¨é¡¶éƒ¨
        ax.invert_yaxis()

        plt.tight_layout()
        output_path = self.output_dir / f"top_{top_n}_keywords.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        return output_path

    def generate_wordcloud(self, keywords_data):
        """ç”Ÿæˆå…³é”®è¯è¯äº‘"""
        # æ ¹æ®è¯„åˆ†æƒé‡ç”Ÿæˆè¯é¢‘
        word_freq = {}
        for kw, data in keywords_data:
            # ä½¿ç”¨è¯„åˆ†ä½œä¸ºæƒé‡
            weight = data['score']
            word_freq[kw] = word_freq.get(kw, 0) + weight

        # ç”Ÿæˆè¯äº‘
        wordcloud = WordCloud(
            width=1600,
            height=800,
            background_color='white',
            colormap='viridis',
            max_words=200,
            relative_scaling=0.5,
            min_font_size=10
        ).generate_from_frequencies(word_freq)

        fig, ax = plt.subplots(figsize=(16, 8))
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis('off')
        ax.set_title('SEOå…³é”®è¯è¯äº‘ï¼ˆå­—ä½“å¤§å°=è¯„åˆ†æƒé‡ï¼‰', fontsize=16, fontweight='bold', pad=20)

        plt.tight_layout(pad=0)
        output_path = self.output_dir / "wordcloud.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight', pad_inches=0.1)
        plt.close()

        return output_path

    def generate_trend_line(self, history_dir="history"):
        """ç”Ÿæˆå†å²è¶‹åŠ¿å›¾"""
        history_files = sorted(Path(history_dir).glob("history_*.json"))

        if len(history_files) < 2:
            print("  âš ï¸  å†å²æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è¶‹åŠ¿å›¾")
            return None

        timestamps = []
        keyword_counts = []
        high_score_counts = []

        for hist_file in history_files:
            try:
                with open(hist_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    timestamps.append(data.get('datetime', '')[:10])  # åªå–æ—¥æœŸ
                    keyword_counts.append(data.get('keywords_count', 0))
                    high_score_counts.append(0)  # å†å²æ•°æ®ä¸­æœªè®°å½•
            except:
                pass

        if not timestamps:
            return None

        fig, ax = plt.subplots(figsize=(12, 6))

        ax.plot(range(len(timestamps)), keyword_counts,
               marker='o', linewidth=2, markersize=8, label='å…³é”®è¯æ€»æ•°', color='steelblue')

        ax.set_xlabel('æ—¶é—´', fontsize=12)
        ax.set_ylabel('å…³é”®è¯æ•°é‡', fontsize=12)
        ax.set_title('å…³é”®è¯æ•°é‡å†å²è¶‹åŠ¿', fontsize=14, fontweight='bold')
        ax.set_xticks(range(len(timestamps)))
        ax.set_xticklabels(timestamps, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3)

        plt.tight_layout()
        output_path = self.output_dir / "historical_trend.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        return output_path

    def generate_summary_dashboard(self, keywords_data, stats):
        """ç”Ÿæˆæ•°æ®æ¦‚è§ˆä»ªè¡¨æ¿"""
        fig = plt.figure(figsize=(16, 10))

        # åˆ›å»ºç½‘æ ¼å¸ƒå±€
        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

        # 1. å…³é”®è¯æ€»æ•°
        ax1 = fig.add_subplot(gs[0, 0])
        ax1.text(0.5, 0.5, f'{stats["total"]}',
                ha='center', va='center', fontsize=48, fontweight='bold', color='steelblue')
        ax1.text(0.5, 0.2, 'å…³é”®è¯æ€»æ•°', ha='center', va='center', fontsize=14)
        ax1.axis('off')

        # 2. é«˜åˆ†å…³é”®è¯æ•°
        ax2 = fig.add_subplot(gs[0, 1])
        high_score = sum(1 for _, d in keywords_data if d['score'] >= 8)
        ax2.text(0.5, 0.5, f'{high_score}',
                ha='center', va='center', fontsize=48, fontweight='bold', color='coral')
        ax2.text(0.5, 0.2, 'é«˜åˆ†å…³é”®è¯(â‰¥8)', ha='center', va='center', fontsize=14)
        ax2.axis('off')

        # 3. å¹³å‡è¯„åˆ†
        ax3 = fig.add_subplot(gs[0, 2])
        avg_score = np.mean([d['score'] for _, d in keywords_data])
        ax3.text(0.5, 0.5, f'{avg_score:.1f}',
                ha='center', va='center', fontsize=48, fontweight='bold', color='green')
        ax3.text(0.5, 0.2, 'å¹³å‡è¯„åˆ†', ha='center', va='center', fontsize=14)
        ax3.axis('off')

        # 4. è¯„åˆ†åˆ†å¸ƒ
        ax4 = fig.add_subplot(gs[1, :])
        scores = [data['score'] for _, data in keywords_data]
        ax4.hist(scores, bins=20, color='skyblue', edgecolor='black', alpha=0.7)
        ax4.set_xlabel('è¯„åˆ†', fontsize=11)
        ax4.set_ylabel('æ•°é‡', fontsize=11)
        ax4.set_title('è¯„åˆ†åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        ax4.grid(axis='y', alpha=0.3)

        # 5. æ„å›¾åˆ†å¸ƒé¥¼å›¾
        ax5 = fig.add_subplot(gs[2, 0])
        intents = [data['intent'].split('/')[0] for _, data in keywords_data]
        intent_counts = Counter(intents)
        ax5.pie(intent_counts.values(), labels=intent_counts.keys(), autopct='%1.1f%%',
                colors=sns.color_palette("Set3", len(intent_counts)))
        ax5.set_title('æ„å›¾åˆ†å¸ƒ', fontsize=12, fontweight='bold')

        # 6. æ•°æ®æºåˆ†å¸ƒ
        ax6 = fig.add_subplot(gs[2, 1])
        sources = [data['source'] for _, data in keywords_data]
        source_counts = Counter(sources)
        sorted_sources = dict(sorted(source_counts.items(), key=lambda x: x[1], reverse=True)[:5])
        ax6.barh(list(sorted_sources.keys()), list(sorted_sources.values()),
                color=sns.color_palette("viridis", len(sorted_sources)))
        ax6.set_xlabel('æ•°é‡', fontsize=11)
        ax6.set_title('æ•°æ®æºåˆ†å¸ƒ', fontsize=12, fontweight='bold')
        ax6.invert_yaxis()

        # 7. TOP10å…³é”®è¯
        ax7 = fig.add_subplot(gs[2, 2])
        top10 = keywords_data[:10]
        keywords_list = [f"{kw[:10]}..." for kw, _ in top10]
        scores_list = [data['score'] for _, data in top10]
        ax7.barh(keywords_list, scores_list, color=plt.cm.RdYlGn_r(np.linspace(0.3, 0.7, 10)))
        ax7.set_xlabel('è¯„åˆ†', fontsize=11)
        ax7.set_title('TOP10å…³é”®è¯', fontsize=12, fontweight='bold')
        ax7.invert_yaxis()

        fig.suptitle('SEOå…³é”®è¯æ•°æ®æ¦‚è§ˆä»ªè¡¨æ¿', fontsize=18, fontweight='bold', y=0.98)

        plt.tight_layout()
        output_path = self.output_dir / "summary_dashboard.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        return output_path

    def generate_all_charts(self, keywords_data, stats=None):
        """ç”Ÿæˆæ‰€æœ‰å›¾è¡¨"""
        print("\nğŸ“Š ç”Ÿæˆæ•°æ®å¯è§†åŒ–å›¾è¡¨...")
        print("-" * 70)

        if stats is None:
            stats = {"total": len(keywords_data)}

        charts = []

        # 1. è¯„åˆ†åˆ†å¸ƒ
        try:
            path = self.generate_score_distribution(keywords_data)
            charts.append(("è¯„åˆ†åˆ†å¸ƒå›¾", path))
            print(f"âœ… è¯„åˆ†åˆ†å¸ƒå›¾: {path}")
        except Exception as e:
            print(f"âš ï¸  è¯„åˆ†åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")

        # 2. æ„å›¾åˆ†å¸ƒé¥¼å›¾
        try:
            path = self.generate_intent_pie(keywords_data)
            charts.append(("æ„å›¾åˆ†å¸ƒé¥¼å›¾", path))
            print(f"âœ… æ„å›¾åˆ†å¸ƒé¥¼å›¾: {path}")
        except Exception as e:
            print(f"âš ï¸  æ„å›¾åˆ†å¸ƒé¥¼å›¾ç”Ÿæˆå¤±è´¥: {e}")

        # 3. æ•°æ®æºåˆ†å¸ƒ
        try:
            path = self.generate_source_bar(keywords_data)
            charts.append(("æ•°æ®æºåˆ†å¸ƒå›¾", path))
            print(f"âœ… æ•°æ®æºåˆ†å¸ƒå›¾: {path}")
        except Exception as e:
            print(f"âš ï¸  æ•°æ®æºåˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")

        # 4. TOP20å…³é”®è¯
        try:
            path = self.generate_top_keywords_bar(keywords_data, top_n=20)
            charts.append(("TOP20å…³é”®è¯å›¾", path))
            print(f"âœ… TOP20å…³é”®è¯å›¾: {path}")
        except Exception as e:
            print(f"âš ï¸  TOP20å…³é”®è¯å›¾ç”Ÿæˆå¤±è´¥: {e}")

        # 5. è¯äº‘
        try:
            path = self.generate_wordcloud(keywords_data)
            charts.append(("è¯äº‘å›¾", path))
            print(f"âœ… è¯äº‘å›¾: {path}")
        except Exception as e:
            print(f"âš ï¸  è¯äº‘å›¾ç”Ÿæˆå¤±è´¥: {e}")

        # 6. å†å²è¶‹åŠ¿
        try:
            path = self.generate_trend_line()
            if path:
                charts.append(("å†å²è¶‹åŠ¿å›¾", path))
                print(f"âœ… å†å²è¶‹åŠ¿å›¾: {path}")
        except Exception as e:
            print(f"âš ï¸  å†å²è¶‹åŠ¿å›¾ç”Ÿæˆå¤±è´¥: {e}")

        # 7. ä»ªè¡¨æ¿
        try:
            path = self.generate_summary_dashboard(keywords_data, stats)
            charts.append(("æ¦‚è§ˆä»ªè¡¨æ¿", path))
            print(f"âœ… æ¦‚è§ˆä»ªè¡¨æ¿: {path}")
        except Exception as e:
            print(f"âš ï¸  æ¦‚è§ˆä»ªè¡¨æ¿ç”Ÿæˆå¤±è´¥: {e}")

        print("-" * 70)
        print(f"âœ… å…±ç”Ÿæˆ {len(charts)} ä¸ªå›¾è¡¨ï¼Œä¿å­˜åœ¨: {self.output_dir}/")

        return charts


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("å¯è§†åŒ–æ¨¡å—æµ‹è¯•...")
    print("è¯·é€šè¿‡ä¸»è„šæœ¬è°ƒç”¨æ­¤æ¨¡å—")
